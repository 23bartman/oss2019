---
title        : Dealing with DevSecOps Findings
type         : working-session
track        : Security Automation
topics       : ["SDL"] ["DevSecOps"] 
technology   : Dependency Check, FindSecBugs, ZAP, Jenkins, Defect Dojo, Selenium, Jira
categories   :                      
featured     : yes                  
when_day     : Tue
when_time    : PM-1,PM-2
room_layout  :
room_id      : room-5
session_slack: 
status       : review-content              # draft, review-content, done
organizers   : Claudio Camerino, Francisco Novo, Rafael Jimenez
participants : 
description  : Hands-on session on how to deal with the security findings generated by automated security testing tools and drive continous improvemnt

---

Security testing is vital to validate the correct implementation of controls and that security requirements. To scale securty testing to often hundreds of different software products, many organisations now implement automated tools to scale security testing practices. In this hands-on working session we'll learn how to build a working DevSecOps POC and, more importantly, how to deal with the myriad of security findings it generates.

## Why

Thanks to the proliferation of automated security scanning tools we are generating a phenomenal amount of security findings. As part of the this session we tackle the following goals.

1. Visibility - Can't secure what you don't see. Why is important to test early in the SDL and map tests to business flows.
2. Accountability - Creating a feedback loop. Why is important to flag findings to their respective owners.
3. Noise Removal - Accuracy drives credibility. Developers are more likely to triage and action reputable findings, starting with tighter scan policies.
4. Scalability - Running tools and managing processes manually is not an option when dealing with hundreds of products. How to scale generation, collection and triaging of security findings.

## What

- Explore the automated testing workflow, participants will be encouraged to take part and share their experience.
- What selection of tools and test types should be used to generate security findings as part of a DevSecOps program.
- Reccommended security testing approaches for:
-- Frontend vs backend applications
-- Static vs runtime
- Why is important to have a single source of truth for multiple testing tools
- AppSec testing integration with QA - user stories vs abuse cases and how to leverage QA processes to drive ZAP.
- Integration with Jira - how to raise and populate SEC type tickets and track their lifecycle.
- Continuous improvement - how to tune security policies as part of the triage process

## Outcomes
- Define ruleset for programmatic removal of noise (i.e. duplicates, transitive dependencies and easy to spot FPs)
- Adapt/hack OSS tools like ZAP, findsecbugs, dependency check and Defect Dojo for enterprise level automation.
- Define roles and responsibilities for these activities based on common industry roles (QA, Del Svcs, Engineering etc.)
- Create scripts to automate generation, collection and allocation of findings.
- Generation of ZAP scan policies and SAST quality profiles (for Sonarqube) for common technologies and frameworks.
- Build a working enterprise scale DevSecOps lab focused on continuous improvement.

## Who

The target audience for this Working Session is:

 - Developers
 - Security professionals
 - DevOps / DevSecOps
 - Security champions
 - AppSec leaders

## Working materials

Here are the current materials for this session:

- [The Security Development Lifecycle](https://www.owasp.org/images/7/78/OWASP_AppSec_Research_2010_Keynote_2_by_Lipner.pdf)
- [SDL in Practice](https://www.owasp.org/images/4/45/SDL_in_practice.pdf)
- [Defect Dojo](https://github.com/DefectDojo/django-DefectDojo)
- [OWASP ZAP](https://github.com/zaproxy/zaproxy)
- [Dependency Check](https://github.com/jeremylong/DependencyCheck)
- [Selenium](https://www.seleniumhq.org/projects/webdriver)

## Previous Summit Working Session
